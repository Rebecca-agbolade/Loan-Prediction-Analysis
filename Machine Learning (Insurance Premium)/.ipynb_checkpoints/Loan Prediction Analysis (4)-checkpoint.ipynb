{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f67c19db",
   "metadata": {},
   "source": [
    "# Library Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc7770db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,sys\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d2f9be",
   "metadata": {},
   "source": [
    "# Data Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42c982ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset Importation\n",
    "ICA = pd.read_csv(\"loan_approval_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4fb853",
   "metadata": {},
   "source": [
    "# Initial Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9072e3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking head of dataset (first 10 rows of the dataset).\n",
    "ICA.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993f2849",
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying the shape\n",
    "ICA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8ad45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic statistics of the dataset\n",
    "ICA.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d456b0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicates\n",
    "ICA.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdd66ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding unique values in the column\n",
    "for i in ICA.columns:\n",
    "    print(\"*******************************************************************\",i,\"************************************************************************\")\n",
    "    print()\n",
    "    print(set(ICA[i].tolist()))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0def3db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking column names\n",
    "ICA.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e2e713",
   "metadata": {},
   "outputs": [],
   "source": [
    "ICA.columns = ICA.columns.str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11644034",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking column names\n",
    "ICA.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daafd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking value count of target variable\n",
    "ICA[\"loan_status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a60241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing unnecessary column\n",
    "ICA = ICA.drop(['loan_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fcbe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "ICA.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c83dc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate IQR for each numerical column\n",
    "Q1 = ICA[numerical_columns].quantile(0.25)\n",
    "Q3 = ICA[numerical_columns].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Print the calculated IQR for each column\n",
    "print(\"Interquartile Range (IQR):\")\n",
    "print(IQR)\n",
    "\n",
    "# Define threshold for outliers\n",
    "lower_threshold = Q1 - 1.5 * IQR\n",
    "upper_threshold = Q3 + 1.5 * IQR\n",
    "\n",
    "# Print the threshold values\n",
    "print(\"\\nLower Threshold for Outliers:\")\n",
    "print(lower_threshold)\n",
    "print(\"\\nUpper Threshold for Outliers:\")\n",
    "print(upper_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d603a0",
   "metadata": {},
   "source": [
    "# Data Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b122332",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(ICA)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703803f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ICA[\"loan_status\"].value_counts()\n",
    "temp_df = pd.DataFrame({\"loan_status\": temp.index, 'values': temp.values})\n",
    "# Using seaborn to create a bar plot\n",
    "sns.barplot(x='loan_status', y='values', data=temp_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2a47e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove leading whitespaces from column names\n",
    "ICA.columns = [col.strip() for col in ICA.columns]\n",
    "\n",
    "\n",
    "independent_attributes = ICA.drop(['loan_status'], axis=1)  # Exclude the target variable\n",
    "\n",
    "# Select a subset of features (adjust as needed)\n",
    "subset_features = ['no_of_dependents', 'income_annum', 'loan_amount', 'cibil_score']\n",
    "\n",
    "# Add the target variable back for visualization\n",
    "subset_data = pd.concat([independent_attributes[subset_features], ICA['loan_status']], axis=1)\n",
    "\n",
    "# Create a pair plot\n",
    "sns.pairplot(subset_data, hue='loan_status', markers=['o', 's'], palette='viridis')\n",
    "plt.suptitle('Pair Plot of Selected Independent Attributes')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1ce556",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for feature in subset_features:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.boxplot(x='loan_status', y=feature, data=ICA)\n",
    "    plt.title(f'Box Plot of {feature} by Loan Status')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d510373d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#distribution of Numerical Columns(why?because i want my data to be normally distributed)\n",
    "numerical_columns = ['no_of_dependents', 'income_annum', 'loan_amount', 'loan_term', 'cibil_score',\n",
    "                      'residential_assets_value', 'commercial_assets_value', 'luxury_assets_value', 'bank_asset_value']\n",
    "\n",
    "# Plot histograms for each numerical column\n",
    "for column in numerical_columns:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.histplot(ICA[column], kde=True, bins=30, color='darkgreen')\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27048df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "numerical_columns = ['no_of_dependents', 'income_annum', 'loan_amount', 'loan_term', 'cibil_score',\n",
    "                      'residential_assets_value', 'commercial_assets_value', 'luxury_assets_value', 'bank_asset_value']\n",
    "# Plot box plots for each numerical column\n",
    "for column in numerical_columns:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.boxplot(x=ICA[column], color='darkgreen')\n",
    "    plt.title(f'Box Plot of {column}')\n",
    "    plt.xlabel(column)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c591095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = ['no_of_dependents', 'income_annum', 'loan_amount', 'loan_term', 'cibil_score',\n",
    "                      'residential_assets_value', 'commercial_assets_value', 'luxury_assets_value', 'bank_asset_value']\n",
    "\n",
    "ICA[numerical_columns].hist(bins=20, figsize=(15, 10))\n",
    "plt.suptitle('Histograms of Numerical Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa373cb",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06821a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "ICA['self_employed'] = label_encoder.fit_transform(ICA['self_employed'])\n",
    "ICA['education'] = label_encoder.fit_transform(ICA['education'])\n",
    "ICA['loan_status'] = label_encoder.fit_transform(ICA['loan_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b4c388",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Showing head of dataset after encoding\n",
    "ICA.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcecfedb",
   "metadata": {},
   "source": [
    "# Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a3b5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical features (excluding the target variable 'Class')\n",
    "numerical_features = [col for col in ICA.columns if col != 'loan_status']\n",
    "# Initialize MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "# Fit and transform the numerical features\n",
    "ICA[numerical_features] = scaler.fit_transform(ICA[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa0c5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking head of dataset after normalisation\n",
    "ICA.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4951b9",
   "metadata": {},
   "source": [
    "# Correlation Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad330ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical features (excluding the target variable 'loan_status')\n",
    "numerical_features = [col for col in ICA.columns if col != 'loan_status']\n",
    "# Select numerical features from the DataFrame\n",
    "numerical_data = ICA[numerical_features]\n",
    "# Calculate the correlation matrix\n",
    "corr_all = numerical_data.corr()\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(corr_all, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df3543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the correlation matrix\n",
    "print(corr_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8838bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for highly Correlated Features\n",
    "# Setting a threshold for high correlation\n",
    "threshold = 0.7\n",
    "# Initializing a list to store highly correlated features pairs\n",
    "highly_correlated_pairs = []\n",
    "# Iterating through the correlation matrix\n",
    "for i in range(len(corr_all.columns)):\n",
    "    for j in range(i+1, len(corr_all.columns)):\n",
    "        if abs(corr_all.iloc[i, j]) > threshold:\n",
    "            # Store the names of highly correlated features\n",
    "            pair = (corr_all.columns[i], corr_all.columns[j])\n",
    "            highly_correlated_pairs.append(pair)\n",
    "if not highly_correlated_pairs:\n",
    "    print(\"No highly correlated features found.\")\n",
    "else:\n",
    "    print(\"Highly correlated feature pairs:\")\n",
    "    for pair in highly_correlated_pairs:\n",
    "        print(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d59446",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0fe64b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  X contains your independent variables and y contains the target variable\n",
    "X = ICA.drop(['loan_status'], axis=1)\n",
    "y = ICA['loan_status']\n",
    "\n",
    "# Split the dataset into 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting sets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedc7506",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80daf803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Define the feature columns (X) and target column (y)\n",
    "x = ICA.drop(columns=['loan_status'])  # Drop 'loan_status' column to get feature columns\n",
    "y = ICA['loan_status']  # Target variable\n",
    "\n",
    "# Select only the numerical columns for scaling (excluding 'loan_status')\n",
    "numerical_columns = ['no_of_dependents', 'income_annum', 'loan_amount', 'loan_term', 'cibil_score',\n",
    "                      'residential_assets_value', 'commercial_assets_value', 'luxury_assets_value',\n",
    "                      'bank_asset_value']\n",
    "\n",
    "# Apply scaling to the numerical columns\n",
    "x[numerical_columns] = scaler.fit_transform(x[numerical_columns])\n",
    "\n",
    "# Display the scaled feature variables (X) and the target variable (y)\n",
    "print(\"Scaled Feature Variables (x):\")\n",
    "print(x.head())\n",
    "\n",
    "print(\"\\nTarget Variable (y):\")\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2706699f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44971a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a LogisticRegression instance\n",
    "logistic_reg = LogisticRegression(random_state=42)\n",
    "\n",
    "# Train the logistic regression model\n",
    "logistic_reg.fit(x_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = logistic_reg.predict(x_test)\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Generate a classification report and print it\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)\n",
    "\n",
    "# Generate a confusion matrix and plot it with a different color map\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis', xticklabels=logistic_reg.classes_, yticklabels=logistic_reg.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c497a063",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "y_prob = logistic_reg.predict_proba(x_test)[:, 1]\n",
    "\n",
    "# Calculate the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "# Calculate the Area Under the ROC Curve (AUC)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Guess')\n",
    "\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR) / Recall / Sensitivity')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225d6f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "model = LogisticRegression(random_state=42)\n",
    "\n",
    "\n",
    "accuracies = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print the accuracy for each fold\n",
    "print(\"Cross-validated Accuracy for each fold:\", accuracies)\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "std_accuracy = np.std(accuracies)\n",
    "\n",
    "# Print mean and standard deviation\n",
    "print(\"Mean Cross-validated Accuracy:\", mean_accuracy)\n",
    "print(\"Standard Deviation of Cross-validated Accuracy:\", std_accuracy)\n",
    "\n",
    "# Additional information\n",
    "min_accuracy = np.min(accuracies)\n",
    "max_accuracy = np.max(accuracies)\n",
    "\n",
    "print(\"Minimum Cross-validated Accuracy:\", min_accuracy)\n",
    "print(\"Maximum Cross-validated Accuracy:\", max_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b4f951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "model = LogisticRegression(random_state=42)\n",
    "\n",
    "\n",
    "accuracies = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "std_accuracy = np.std(accuracies)\n",
    "\n",
    "# Plot the distribution of accuracies\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(accuracies, bins=10, kde=True, color='skyblue')\n",
    "plt.axvline(x=mean_accuracy, color='red', linestyle='--', label=f'Mean Accuracy: {mean_accuracy:.3f}\\nStd Deviation: {std_accuracy:.3f}')\n",
    "plt.title('Distribution of Cross-validated Accuracies')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a16a746",
   "metadata": {},
   "source": [
    "# DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea37cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a DecisionTreeClassifier instance\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the decision tree model\n",
    "decision_tree.fit(x_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = decision_tree.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Generate a classification report\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Generate a confusion matrix with a different color map (e.g., 'viridis')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis')  # Change 'viridis' to your preferred colormap\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Print evaluation metrics separately\n",
    "print(\"Decision Tree Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\\n\", classification_rep)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc24931",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a DecisionTreeClassifier instance with 'entropy' as the criterion\n",
    "decision_tree_entropy = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "\n",
    "# Train the decision tree model\n",
    "decision_tree_entropy.fit(X_train, y_train)\n",
    "\n",
    "# Plot the decision tree\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(decision_tree_entropy, feature_names=X_train.columns, class_names=['Rejected', 'Approved'], filled=True, rounded=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c40f912",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Create a DecisionTreeClassifier instance\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "accuracies_decision_tree = cross_val_score(decision_tree, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print the accuracy for each fold\n",
    "print(\"Cross-validated Accuracy for each fold:\", accuracies_decision_tree)\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "mean_accuracy_decision_tree = np.mean(accuracies_decision_tree)\n",
    "std_accuracy_decision_tree = np.std(accuracies_decision_tree)\n",
    "\n",
    "# Print mean and standard deviation\n",
    "print(\"Mean Cross-validated Accuracy (Decision Tree):\", mean_accuracy_decision_tree)\n",
    "print(\"Standard Deviation of Cross-validated Accuracy (Decision Tree):\", std_accuracy_decision_tree)\n",
    "\n",
    "# Additional information\n",
    "min_accuracy_decision_tree = np.min(accuracies_decision_tree)\n",
    "max_accuracy_decision_tree = np.max(accuracies_decision_tree)\n",
    "\n",
    "print(\"Minimum Cross-validated Accuracy (Decision Tree):\", min_accuracy_decision_tree)\n",
    "print(\"Maximum Cross-validated Accuracy (Decision Tree):\", max_accuracy_decision_tree)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create a DecisionTreeClassifier instance\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Assuming you have your feature matrix (X) and target variable (y)\n",
    "# Replace 'X' and 'y' with your actual feature matrix and target variable\n",
    "accuracies_decision_tree = cross_val_score(decision_tree, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Plot the distribution of accuracies using a histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(accuracies_decision_tree, bins=10, kde=True, color='skyblue')\n",
    "plt.title('Distribution of Cross-validated Accuracies (Decision Tree)')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87524ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "# Create a LogisticRegression instance\n",
    "model = LogisticRegression(random_state=42)\n",
    "\n",
    "\n",
    "accuracies = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "std_accuracy = np.std(accuracies)\n",
    "\n",
    "# Plot the distribution of accuracies\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(accuracies, bins=10, kde=True, color='skyblue', element='step', stat='density')\n",
    "plt.axvline(x=mean_accuracy, color='red', linestyle='--', label=f'Mean Accuracy: {mean_accuracy:.3f}\\nStd Deviation: {std_accuracy:.3f}')\n",
    "plt.title('Distribution of Cross-validated Accuracies (Logistic Regression)')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7174b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create an SVC (Support Vector Classification) instance\n",
    "svm_classifier = SVC(random_state=42)\n",
    "\n",
    "# Train the SVM model\n",
    "svm_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = svm_classifier.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Generate a classification report\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Generate a confusion matrix with a different color map (e.g., 'viridis')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis')  # Change 'viridis' to your preferred colormap\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Print evaluation metrics separately\n",
    "print(\"SVM Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\\n\", classification_rep)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f694d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create an SVC (Support Vector Classification) instance\n",
    "svm_classifier = SVC(random_state=42)\n",
    "\n",
    "# Train the SVM model\n",
    "svm_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Predict probabilities for the positive class (class 1)\n",
    "y_prob = svm_classifier.decision_function(x_test)\n",
    "\n",
    "# Calculate the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "# Calculate the Area Under the ROC Curve (AUC)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Guess')\n",
    "\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR) / Recall / Sensitivity')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d56fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Create an SVC (Support Vector Classification) instance\n",
    "svm_classifier = SVC(random_state=42)\n",
    "\n",
    "\n",
    "accuracies_svm = cross_val_score(svm_classifier, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "mean_accuracy_svm = np.mean(accuracies_svm)\n",
    "std_accuracy_svm = np.std(accuracies_svm)\n",
    "\n",
    "# Plot the distribution of accuracies\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(accuracies_svm, bins=10, kde=True, color='skyblue', element='step', stat='density')\n",
    "plt.axvline(x=mean_accuracy_svm, color='red', linestyle='--', label=f'Mean Accuracy: {mean_accuracy_svm:.3f}\\nStd Deviation: {std_accuracy_svm:.3f}')\n",
    "plt.title('Distribution of Cross-validated Accuracies (SVM)')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cc1b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a KNeighborsClassifier instance with a specified number of neighbors (e.g., n_neighbors=5)\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the KNN model\n",
    "knn_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = knn_classifier.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Generate a classification report\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Generate a confusion matrix with a different color map (e.g., 'viridis')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis')  # Change 'viridis' to your preferred colormap\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Print evaluation metrics separately\n",
    "print(\"K-Nearest Neighbors Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80ce873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a KNeighborsClassifier instance with a specified number of neighbors (e.g., n_neighbors=5)\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the KNN model\n",
    "knn_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Predict probabilities for the positive class (class 1)\n",
    "y_prob = knn_classifier.predict_proba(x_test)[:, 1]\n",
    "\n",
    "# Calculate the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "# Calculate the Area Under the ROC Curve (AUC)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Guess')\n",
    "\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR) / Recall / Sensitivity')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42fd19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Create a KNeighborsClassifier instance with a specified number of neighbors (e.g., n_neighbors=5)\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "\n",
    "accuracies_knn = cross_val_score(knn_classifier, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "mean_accuracy_knn = np.mean(accuracies_knn)\n",
    "std_accuracy_knn = np.std(accuracies_knn)\n",
    "\n",
    "# Plot the distribution of accuracies\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(accuracies_knn, bins=10, kde=True, color='skyblue', element='step', stat='density')\n",
    "plt.axvline(x=mean_accuracy_knn, color='red', linestyle='--', label=f'Mean Accuracy: {mean_accuracy_knn:.3f}\\nStd Deviation: {std_accuracy_knn:.3f}')\n",
    "plt.title('Distribution of Cross-validated Accuracies (K-Nearest Neighbors)')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05dd200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create an XGBClassifier instance\n",
    "xgb_classifier = XGBClassifier(random_state=42)\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgb_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = xgb_classifier.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Generate a classification report\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Generate a confusion matrix with a different color map ( 'viridis')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis')  \n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Print evaluation metrics separately\n",
    "print(\"XGBoost Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713d3000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create an XGBClassifier instance\n",
    "xgb_classifier = XGBClassifier(random_state=42)\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgb_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Predict probabilities for the positive class (class 1)\n",
    "y_prob = xgb_classifier.predict_proba(x_test)[:, 1]\n",
    "\n",
    "# Calculate the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "# Calculate the Area Under the ROC Curve (AUC)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Guess')\n",
    "\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR) / Recall / Sensitivity')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5e8735",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Create an XGBClassifier instance\n",
    "xgb_classifier = XGBClassifier(random_state=42)\n",
    "\n",
    "accuracies_xgb = cross_val_score(xgb_classifier, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "mean_accuracy_xgb = np.mean(accuracies_xgb)\n",
    "std_accuracy_xgb = np.std(accuracies_xgb)\n",
    "\n",
    "# Plot the distribution of accuracies\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(accuracies_xgb, bins=10, kde=True, color='skyblue', element='step', stat='density')\n",
    "plt.axvline(x=mean_accuracy_xgb, color='red', linestyle='--', label=f'Mean Accuracy: {mean_accuracy_xgb:.3f}\\nStd Deviation: {std_accuracy_xgb:.3f}')\n",
    "plt.title('Distribution of Cross-validated Accuracies (XGBoost)')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5f08db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Gaussian Naive Bayes classifier\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Train the Naive Bayes model\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Generate a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap= 'viridis')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix (Naive Bayes)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088039ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Create a Gaussian Naive Bayes classifier\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "\n",
    "accuracies_nb = cross_val_score(nb_classifier, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "mean_accuracy_nb = np.mean(accuracies_nb)\n",
    "std_accuracy_nb = np.std(accuracies_nb)\n",
    "\n",
    "# Plot the distribution of accuracies\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(accuracies_nb, bins=10, kde=True, color='skyblue', element='step', stat='density')\n",
    "plt.axvline(x=mean_accuracy_nb, color='red', linestyle='--', label=f'Mean Accuracy: {mean_accuracy_nb:.3f}\\nStd Deviation: {std_accuracy_nb:.3f}')\n",
    "plt.title('Distribution of Cross-validated Accuracies (Naive Bayes)')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7830642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Gaussian Naive Bayes classifier\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Train the Naive Bayes model\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities on the test set\n",
    "y_prob = nb_classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate the false positive rate, true positive rate, and thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "# Calculate the Area Under the ROC Curve (AUC)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.2f}')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('ROC Curve (Naive Bayes)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1950c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed276502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35639c07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
